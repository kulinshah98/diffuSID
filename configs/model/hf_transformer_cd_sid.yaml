## Loads a T5 encoder model per domain from Hugging Face for multiple domains.


defaults:
  - hf_transformer
  - huggingface_model/t5_encoder@domain_models.16
  - huggingface_model/t5_encoder@domain_models.17
  - _self_

_target_: src.models.internal.modules.huggingface.transformer_module_cross_domain_sparse_id.CDSIDTransformerModule

# setting this to 5 such that cross domain model roughly has the same number of parameters
huggingface_model:
  config:
    num_heads: 4
    num_layers: 1

domain_models:
  '16': # DISCOVER_FEED
   config:
    num_heads: 4
    num_layers: 1
    vocab_size: 0 # setting this to 0 to prevent the model from using the vocab
  '17': # SPOTLIGHT_FEED
   config:
    num_heads: 4
    num_layers: 1
    vocab_size: 0 # setting this to 0 to prevent the model from using the vocab

feature_to_model_input_map:
  sequencefeature_unified_static__creator_id__categorical_vocab: input_ids
  sequencefeature_unified_static__page_type__categorical_vocab: domain_ids

masking_token: ${data_loading.train_dataloader_config.dataloader.masking_token}
