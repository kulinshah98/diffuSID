SHELL := /bin/bash
export PYTHONPATH := .:$(PYTHONPATH)

current_date=$(date +%Y-%m-%d)
current_time=$(date +%H-%M-%S)

TIMESTAMP := $(shell date +%Y-%m-%d/%H-%M-%S)
TIMESTAMP_WITHOUT_SPECIAL_CHARACTERS := $(shell echo $(TIMESTAMP) | sed 's/[-\/:]//g')
# Default version to track commit hash and username during development
# change this to latest at final deployment

# example: make push-base-docker image_version=latest
USERNAME := $(shell whoami)
COMMIT_HASH := $(shell git rev-parse --short HEAD)

# timestamp makes sure multiple jobs spinned at the same time won't mess with each others images
torch_version := 2.5
task := train

gpu_type := t4
gpu_count := 4
num_nodes := 1
# if debug_hydra is true, it will run the hydra command with --cfg all which just prints the config
debug_hydra := false
print_config_suffix := $(shell if [ $(debug_hydra) = true ]; then echo "--cfg all"; else echo ""; fi)
test_file := ""
coverage_file := .coverage

# This function allows for us to add a suffix to the job id.
define append_job_id_suffix
$(if $(job_id_suffix),-$(job_id_suffix),)
endef


help:  ## Show help
	@grep -E '^[.a-zA-Z_-]+:.*?## .*$$' $(MAKEFILE_LIST) | awk 'BEGIN {FS = ":.*?## "}; {printf "\033[36m%-30s\033[0m %s\n", $$1, $$2}'

clean: ## Clean autogenerated files
	rm -rf dist
	find . -type f -name "*.DS_Store" -ls -delete
	find . | grep -E "(__pycache__|\.pyc|\.pyo)" | xargs rm -rf
	find . | grep -E ".pytest_cache" | xargs rm -rf
	find . | grep -E ".ipynb_checkpoints" | xargs rm -rf
	rm -f .coverage

clean-logs: ## Clean logs
	rm -rf logs/**

format: ## Run pre-commit hooks
	pre-commit run -a

test-full: ## Run all tests
	pytest

test-file:
	pytest ${test_file}

train: ## Train the model
	python src/train.py ${ARGS} ${print_config_suffix}

train-gpu:
	python src/train.py trainer=ddp ${ARGS} ${print_config_suffix}

inference: ## Run inference on the model
	python src/inference.py ${ARGS} ${print_config_suffix}

inference-gpu:
	python src/inference.py trainer=ddp ${ARGS} ${print_config_suffix}

generate-docs: ## Generate Readme files for yamls
	python scripts/document_yamls.py

generate-coverage-for-trimmed-repo:
	coverage run -m src.train ++should_skip_retry=True ${ARGS}

combine-coverage-files:
	coverage combine

extract-used-code:
	python tools/extract_used_code.py --data-file ${coverage_file} --out-dir trimmed_repo

detect-used-lines:
	python tools/detect_used_lines.py --data-file ${coverage_file}
